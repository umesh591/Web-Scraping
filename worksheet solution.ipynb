{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEB SCRAPING\n",
    "WORKSHEET – 1\n",
    "\n",
    "Solution\n",
    "\n",
    "In Q1 to Q9, only one option is correct, Choose the correct option:\n",
    "1.\tWhich of the following extracts information from user generated content?\n",
    "A)\tJava script tagging\tB) Web scraping\n",
    "C) A/B testing\tD) MROCs\n",
    "\n",
    "Ans – Web Scraping\n",
    "\n",
    "2.\tWhich of the following is not a web scraping library in python?\n",
    "A)\tselenium\tB) Beautiful soup\n",
    "C) Requests\tC) scrapy\n",
    "\n",
    "Ans - Request\n",
    "\n",
    "3.\tSelenium tests \t?\n",
    "A)\tBrowser based applications\tB) DOS applications\n",
    "C) GUI applications\tD) All of the above\n",
    "\n",
    "Ans – All of  the above \n",
    "\n",
    "4.\tTask of crawling is performed by a complex software which is known as:\n",
    "A)\tScraper\tB) Crawler\n",
    "C) Boat\tD) Spider\n",
    "\n",
    "               Ans - Spider\n",
    "\n",
    "5.\tWhich of the following commands is used to access name of a tag in Beautiful Soup?\n",
    "A)\ttag.attrs\tB) tag.name\n",
    "C) tag,id\tC) tag[‘id’]\n",
    "\n",
    "Ans  - tag.attrs\t\n",
    "\n",
    "6.\tWhich of the following is the default parser in Beautiful Soup?\n",
    "A)\thtml.parser\tB) html5lib\n",
    "C) lxml\tD) lxml-xml\n",
    "\n",
    "              Ans -  lxml\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "7.\tIn selenium the webdriver is used to?\n",
    "A)\tdesign a test using selenese\n",
    "B)\ttest a web application on firefox only\n",
    "C)\texecute tests on HtmlUnit browser\n",
    "D)\tto download any content from a webpage\n",
    "\n",
    "Ans - Execute tests on HtmlUnit browser\n",
    "\n",
    "\n",
    "8.\tIn selenium, driver.find_elements_by_xpath(‘given xpath’) returns:\n",
    "A)\tthe first webelement associated with the ‘given xpath’\n",
    "B)\tthe url of first webelement associated with the ‘given xpath’\n",
    "C)\tthe list of all webelements associated with the ‘given xpath’\n",
    "D)\tall the attributes of the first webelement associated with the ‘given xpath’\n",
    "\n",
    "Ans - All the attributes of the first webelement associated with the ‘given xpath’\n",
    "\n",
    "\n",
    "9.\tThe script ‘window.scrollBy(0,a) scrolls the webpage by?\n",
    "A)\t‘a’ number of horizontal spaces\n",
    "B)\t‘a’ number of lines\n",
    "C)\t‘a’ number of pixels horizontally\n",
    "D)\t‘a’ number of pixels vertically\n",
    "\n",
    "Ans - ‘a’ number of pixels vertically\n",
    "\n",
    "\n",
    "In Q10, more than one options are correct, Choose all the correct options:\n",
    "\n",
    " 10.\tWhich of the following is(are) tags of HTML?\n",
    "A)\t<a>\tB) <b>\n",
    "C) <image>\tD) <href>\n",
    "\n",
    "\n",
    "Ans -  <a> <image> <b>  \n",
    "\n",
    "\n",
    "Q10 to Q13 are subjective answer type questions, Answer them briefly.\n",
    "11.\tWhat is the main difference between a web scraper and a web crawler?\n",
    "Ans – Web Scraping is a technique used to extract data from websites and web Scraper does not follow  robots,txt rules and web crawler is used for indexing of web pages  it visits each and every page and it follow robots.txt rule\n",
    "\n",
    "12.\tWhat is ‘robots.txt’ file? What is the use of ‘robots.txt’ file?\n",
    "\n",
    "Ans - It is a file which contain allow and disallow  pages  if it is disallow  we can not  crawl that website page because when we crawl the data , It will read the robots,txt file first.\n",
    "\n",
    "13.\tWhat are static and dynamic web pages?\n",
    "\n",
    "Ans –  In static web pages  database is not used and the complexity of static pages are less and it display same content for every user and the dynamic web pages display different content  for every user and in dynamic web pages database is used and the complexity is high.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=driver.page_source\n",
    "soup=BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Q14 and Q15 are programming practice questions. Solve it using JUPYTER NOTEBOOK and paste the solution in your answer sheets.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>14.\tWrite a python program to check whether a webpage contains a title or not.</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Title Scraping</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title(url):\n",
    "    driver.get(url)\n",
    "    content=driver.page_source\n",
    "    soup=BeautifulSoup(content)\n",
    "    data =soup.find('title')\n",
    "    if(data):\n",
    "        print(\"Title of this page => \",data.text)\n",
    "    else:\n",
    "        print(\"The url has no title\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of this page =>  Online Shopping Site for Mobiles, Electronics, Furniture, Grocery, Lifestyle, Books & More. Best Offers!\n"
     ]
    }
   ],
   "source": [
    "title(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Access the search bar and search button on images.google.com.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search =driver.find_element_by_css_selector('input[name=q]')\n",
    "search.send_keys(\"ghost\")\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = soup.find('span' , attrs={'class':'_35KyD6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
